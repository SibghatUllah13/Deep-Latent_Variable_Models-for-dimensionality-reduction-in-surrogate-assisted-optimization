{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyDOE\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.stats.distributions as dist\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from collections import namedtuple\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Elastic Net Regression '''\n",
    "def elastic_net(train_data,test_data):\n",
    "    scaler =  MinMaxScaler().fit(np.r_[train_data.iloc[:,:-1].values])\n",
    "    regr = ElasticNet(alpha= 0.199 ,random_state=0 , l1_ratio=0.95, fit_intercept =True, max_iter=3000,selection='random').fit(scaler.transform ( np.array(train_data.iloc[:,:-1])) ,  np.array(train_data.iloc[:,-1]))\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    return regr,pred\n",
    "\n",
    "\n",
    "''' Kriging'''\n",
    "def kriging(train_data,test_data):\n",
    "    kernel =  RBF()\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:-1].values])\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer= 15,random_state=0,\n",
    "                                   normalize_y=True ).fit(scaler.transform(train_data.iloc[:,:-1]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    return gpr,pred\n",
    "\n",
    "''' KNN Regression Implementation'''\n",
    "def KNN(train_data,test_data):\n",
    "    scaler = MinMaxScaler().fit(np.r_[train_data.iloc[:,:-1].values])\n",
    "    regr = KNeighborsRegressor(n_neighbors=31,weights='distance',algorithm='brute',p=2\n",
    "                               ).fit(scaler.transform(train_data.iloc[:,:-1]), train_data.iloc[:,-1])\n",
    "\n",
    "    pred = regr.predict(scaler.transform(test_data))\n",
    "    return regr,pred\n",
    "\n",
    "\n",
    "''' Support Vector Regression'''\n",
    "def _SVR(train_data,test_data):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler().fit(np.r_[train_data.iloc[:,:-1].values])\n",
    "    gpr = sklearn.svm.SVR(kernel='rbf', gamma = 69.69 , C = 1000.000000 ,max_iter=1500).fit( scaler.transform(train_data.iloc[:,:-1]), train_data.iloc[:,-1])\n",
    "    pred = gpr.predict(scaler.transform(test_data))\n",
    "    return gpr,pred\n",
    "\n",
    "\"\"\" Generating Polynomial Features i.e., Function Basis \"\"\"\n",
    "def quadratic_polynomial (df):\n",
    "    return pd.DataFrame(PolynomialFeatures(degree=2).fit_transform(df))\n",
    "\n",
    "\"\"\" Quadratic Regression with Elastic Net Penalty\"\"\"\n",
    "def polynomial(tr, te):\n",
    "    f_original = train['Y']\n",
    "    true = test['Y']\n",
    "    temp1 = quadratic_polynomial (tr.iloc[:,:-1])\n",
    "    temp2 = quadratic_polynomial (te.iloc[:,:-1])\n",
    "    temp1 ['Y'] = f_original\n",
    "    model_eln , pred_eln = elastic_net(temp1,temp2)\n",
    "    return model_eln , pred_eln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Test Data Set initially Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data Sets\\\\Original\\\\100 D\\\\Training_Data_Sets\\\\train_3_2000Samples.csv\"\n",
    "train_y = pd.read_csv(path).iloc[:,-1]\n",
    "test_y = pd.read_csv(path[:-42]+str('Test_Data_Sets\\\\test_3_400Samples.csv')).iloc[:,-1]\n",
    "path = \"Data Sets\\\\Latent\\\\50 %\\\\100 D\\\\Training_Data_Sets\\\\latent_100D.csv\"\n",
    "train = pd.read_csv(path, index_col = 0)\n",
    "test = pd.read_csv(path[:-34]+str('Test_Data_Sets\\\\latent_100D.csv'), index_col = 0)\n",
    "train ['Y'] = train_y\n",
    "test ['Y'] = test_y\n",
    "del train_y\n",
    "del test_y\n",
    "true = np.array(test['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 ms ± 955 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model_knn ,pred_knn = KNN(train,test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.271379591313256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn ,pred_knn = KNN(train,test.iloc[:,:-1])\n",
    "np.mean((abs(true-pred_knn) / abs(true) ) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 ms ± 1.38 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%timeit model_svr , pred_svr = _SVR(train,test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sefi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.09270321925604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svr , pred_svr = _SVR(train,test.iloc[:,:-1])\n",
    "np.mean((abs(true-pred_svr) / abs(true) ) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 s ± 1.15 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model_kri , pred_kri = kriging(train,test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.158135470928208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kri , pred_kri = kriging(train,test.iloc[:,:-1])\n",
    "np.mean((abs(true-pred_kri) / abs(true) ) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 ms ± 9.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit polynomial (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.442970983778178"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eln , pred_eln = polynomial (train,test)\n",
    "np.mean((abs(true-pred_eln) / abs(true) ) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2_accuracy = pd.DataFrame([true, pred_eln , pred_knn , pred_kri , pred_svr]).T\n",
    "F2_accuracy.columns = ['True' , 'ELN' ,  'KNN' ,  'Kri',  'SVR']\n",
    "F2_accuracy.to_csv('Results\\\\F3_Accuracy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
